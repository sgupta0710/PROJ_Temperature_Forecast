---
title: "HarvardX: PH125.9x Data Science  \n   Temperature Forecasting"
author: "Sakshi Gupta"
date: "22/12/2020"
output: 
 pdf_document:
    toc: true
    toc_depth: 3
    number_sections: true
---


\newpage







# Introduction
This is the report on Temperature Forecast.This is the capstone report of the HarvardX: Data Science- Capstone course project 2.

# Objective
In this project, We have to predict the maximum temperature of the last day of the year. We have the temperature historical data of the whole year which will be used in prediction. This is machine learning problem, using supervised learning.
Supervised learning can be described as taking an input vector comprised of n-features
and mapping it to an associated target value or class label.

# Data
The original data was obtained from National Centers for Environmental Prediction and can be found at https://www.ncep.noaa.gov/ 

## Loading of Data
The data can be loaded by the below code. We will split the complete data into train set and test set. 
we will train our model on the train set and test it on the test set

```{r message=FALSE}
##########################################################

# Note: this process could take a couple of minutes

if(!require(tidyverse)) install.packages("tidyverse", repos = "http://cran.us.r-project.org")
if(!require(caret)) install.packages("caret", repos = "http://cran.us.r-project.org")
if(!require(data.table)) install.packages("data.table", repos = "http://cran.us.r-project.org")
if(!require(data.table)) install.packages("randomForest", repos = "http://cran.us.r-project.org")


#loading libraries
library(tidyverse)
library(caret)
library(data.table)
library(lubridate)
library(dplyr)
library(randomForest)

dates<- read.csv('temps_new.csv' , stringsAsFactors = TRUE)
str(dates)

```

Data Columns/ Attributes  
1. Year : 2019  
2. Month : Number for month of the year  
3. Day : Number for day of the year  
4. week : Day of the week as a chracter string  
5. temp_2 : Max. Temperature 2 days prior  
6. temp_1 : Max. Temperature 1 days prior  
7. average : Historical average max temperature  
8. actual : Actual Max temperature   
9. Friend : Friend's prediction, a random number between 20 below the average and 20 above the average   

# Data Preperation
If we observe the data we will see that there are total 348 rows whereas in a year we have 365 days. That means we have less data as expected, but since this is not a big number,missing data will not have large effect.
Also, this data is from a very trusted source we can say that the data quality is good.
The data has 9 columns with 8 features and one target - "actual"

# Exploratory Data Analysis

## Data Pre-processing
Preprocessing steps

1. One-hot coding
2. split data - into features and labels
3. Split data into training and tests sets

Identify anomalies in each column of the dataset using Summary
```{r }
summary(dates)
```

Just by looking at the summary of the data, it becomes difficult to find out any anomalities. But by using the graphs, any anomalities looks clearly.

``` {r }
plot(dates$actual, type = "l", ylab = "Temperature", xlab = " ", main = "Max Temp")
plot(dates$temp_1, type = "l", ylab = "Temperature", xlab = " ", main= "Previous Day Max Temp")
plot(dates$temp_2, type = "l", ylab = 'Temperature', xlab = 'Date',  main= "Two Days Prior Max Temp")
plot(dates$friend, type = "l", ylab = "Temperature", main= "Friend Estimate")
```

Let's convert the seperated dates to single date.

```{r }
years <- dates$year
months <- dates$month
day <- dates$day
```


Now lets convert them to date format now.

```{r }
date <- dates %>%
  mutate(date = make_date(year, month, day))
```


Lets start pre-processing the data  

### 1. one hot coding - using dummyvars of caret package

What is one-hot coding?
It takes input as categorical data and converts them to the numerical data without any ordering

```{r }
dmy <- dummyVars(" ~ .", data = dates)
newdates <- data.frame(predict(dmy, newdata = dates))
glimpse(newdates)
```

### 2. Split dataframe into features and target
Features are the columns used to make predctions and labels are the target which we have to predict

```{r }
features <- newdates %>% select('year','month','day','week.Fri','week.Mon','week.Sat','week.Sun','week.Thurs', 'week.Tues' ,'week.Wed' ,'temp_2' ,'temp_1' , 'average' , 'friend')
target <- newdates %>% select('actual')
```

### 3. Split data into train and test set

We will split the data into train and test set and will use the train set to train the model and test set will be used to validate the model.

```{r message=FALSE}
set.seed(1, sample.kind = "Rounding")  # if using R 3.5 or earlier, use `set.seed(1)`
test_index <- createDataPartition(y= newdates$actual, times = 1, p = 0.25, list = FALSE)

train_set <- newdates[-test_index,]
test_set <- newdates[test_index,]
```


Analyse the train set and test set
```{r }
summary(train_set)
summary(test_set)
```

Lets check the number of days in each month in the dataset
```{r}
newdates %>% group_by(month) %>% summarise(n = n())
```

Check any NA value in the dataset
```{r}
anyNA(train_set)
anyNA(test_set)
```

Fetch all the column names except target column name 'actual' in the list for using them in future
```{r }
featuresCols <- colnames(newdates[-14])
```


# Model Building
Lets calculate the base model using the result of which we can see how can we improve our further models

## 1. Simple Average Model

```{r }
base_avg_values_test <- test_set[ , "average"]
base_actual_values_test <- test_set[ , "actual"]


base_err <- abs(base_avg_values_test  - base_actual_values_test)
#calculate the average base error in degrees
mean_avg <- mean(base_err)
mean_avg  

#calculate the MAPE -Mean absolute percentage error
mape_avg = 100 * (mean_avg / base_actual_values_test)

#accuracy
accuracy_avg = 100 - mean(mape_avg)
accuracy_avg

```

Lets save this observed values in a table and keep on adding more to this table to analyse the best model

```{r message=FALSE}
predicted_results <- data_frame(Date = "31-12-2019" , Method = "Average Model appraoch",  Error = mean_avg , Accuracy = accuracy_avg)
predicted_results %>% knitr::kable()
```

With this avg we get the forecast with an error of 4.51 degrees and accuracy of 92.4%.
This is our baseline error and now we have to build such model which will give us less error than this base error

Now lets train our model using

## 2. RANDOM FOREST

Random forest is an ensemble-based learning algorithm which is comprised of n
collections of de-correlated decision trees [10]. It is built off the idea of bootstrap
aggregation, which is a method for resampling with replacement in order to
reduce variance.Random Forest uses multiple trees to average for regression in the terminal leaf nodes when making a prediction. 

Because of the idea of decision trees, random forest models have resulted
in significant improvements in prediction accuracy as compared to other models


```{r message=FALSE }
set.seed(22, sample.kind = 'Rounding')
temp.rf <- randomForest(actual ~ . , data = train_set, 
                        importance = TRUE, na.action = na.omit)

temp.rf
```

Lets check the predictions
```{r }
pred = predict(temp.rf, newdata = test_set)
```

Now lets calculate the absolute error between the predicted values and the actual value
```{r}
abs_erre_rf <- abs(pred - base_actual_values_test)
```

take the mean of absolute error 
```{r}
abs_mean_rf <- mean(abs_erre_rf)
abs_mean_rf 

#calculate MAPE- Mean absolute percentage error
mape = 100 * (abs_erre_rf / base_actual_values_test)


#accuracy
accuracy = 100 - mean(mape)
accuracy  

```

Adding this to the results table

```{r}
predicted_results <- bind_rows(predicted_results,data_frame(Date = "31-12-2019" , Method = "Random_forest",  Error = abs_mean_rf , Accuracy = accuracy))
predicted_results %>% knitr::kable()
```


Here we observed that the new model has improved the error.

Now we will calculate MAPE- Mean absolute percentage error
```{r }
mape = 100 * (abs_erre_rf / base_actual_values_test)
```

Lets calculate the accuracy of this model
```{r }
accuracy = 100 - mean(mape)
accuracy 
```

Lets work on improving this model by randomly tunning some parameters
```{r message=FALSE}
set.seed(1, sample.kind = "Rounding")
temp.rf_new <- randomForest(actual ~ . , data = train_set, mtry=4 ,ntree = 120,
                        importance = TRUE, na.action = na.omit)

temp.rf_new
```


Lets check the predictions for this tuned model
```{r }
pred_new = predict(temp.rf_new, newdata = test_set)
```

now lets calculate the absolute error between the predicted values and the actual value
```{r }
abs_erre_rf_new <- abs(pred_new - base_actual_values_test)
```

take the mean of absolute error 
```{r}
abs_mean_rf_new <- mean(abs_erre_rf_new)
abs_mean_rf_new  


#calculate MAPE- Mean absolute percentage error
mape_new = 100 * (abs_erre_rf_new / base_actual_values_test)


#accuracy
accuracy_new = 100 - mean(mape_new)
accuracy_new 
```

Adding these values also to the results table

```{r}
predicted_results <- bind_rows(predicted_results, data_frame(Date = "31-12-2019" , Method = "Random_forest_improved",  Error = abs_mean_rf_new , Accuracy = accuracy_new ))

predicted_results %>% knitr::kable()
```


Here we observed that the new model has further improved the error.
Similarly we can tune other hyperparameters as well

# Variable importance 
## Variable importance and feature selection

By now we have made a good model which is giving us improved error values. Now on observing, we can see that there are many features which are not contributing much in the prediction of the temperature. Here we need to identify which are the top features which are contributing in the better prediction and making the model much improved

```{r }
importance(temp.rf)
```

we see received two paramenters - %IncMSE & IncNodePurity

Mean Decrease Accuracy (%IncMSE) - This shows how much our model accuracy decreases if we leave out that variable.The higher number, the more important the feature is.

IncNodePurity - This is a measure of variable importance based on the Gini impurity index used for the calculating the splits in trees.

So the two important features are 
1.temp_1- the maximum temperature the day before 
2.average - the historical avg max temperature

The day of the week and the year are not contributing much in predicting the max temperature as it has nothing to do with the temperature
To improve our model we will only consider these two paramenters and calculate the error

## Model only with important features 
Here we can remove all other variables which has no/less importance and build the model

```{r message=FALSE}
imp_var <- c('temp_1','average','actual')

train_imp <- train_set[ , imp_var]
test_imp <- test_set[ , imp_var]
set.seed(22,sample.kind = "Rounding")
temp.rf_imp <- randomForest(actual ~ . , data = train_imp, mtry=2 ,ntree = 100,
                                          importance = TRUE, na.action = na.omit)
temp.rf_imp

```


Lets check the predictions of this model
```{r }
pred_imp = predict(temp.rf_imp, newdata = test_imp)

#now lets calculate the absolute error between the predicted values and the actual value
abs_erre_rf_imp <- abs(pred_imp - base_actual_values_test)

#take the mean of absolute error 
abs_mean_rf_imp <- mean(abs_erre_rf_imp)
abs_mean_rf_imp   

#calculate MAPE- Mean absolute percentage error
mape_imp = 100 * (abs_erre_rf_imp / base_actual_values_test)


#accuracy
accuracy_imp = 100 - mean(mape_imp)
accuracy_imp
```

Adding these values to results table
```{r}
predicted_results <- bind_rows(predicted_results, data_frame(Date = "31-12-2019" , Method = "Random_forest_with_imp_features",  Error = abs_mean_rf_imp , Accuracy = accuracy_imp ))

predicted_results %>% knitr::kable()
```


On taking just the imp variables/features we have seen that the performance is almost similar infact little improved as it is when all the variables were considered.
In real life project, if we work on all the variables, model will take more time and memory and will give same result, hence it is advisable that before applying the model, we should identify the most important variables/features which will majorly contribute in the prediction. 

## Visualization -final after model
Lets visualize the importance of the features 
```{r }
varImpPlot(temp.rf, sort = TRUE)
```

Lets visualize the same in historgram

```{r message=FALSE}
imp1 = as.data.frame(importance(temp.rf))
imp1 = cbind(vars=rownames(imp1), imp1)
testing <- imp1[2]
imp1 = imp1[order(testing),]
imp1$vars = factor(imp1$vars, levels=unique(imp1$vars))
imp1 %>% ggplot(aes(imp1$vars ,imp1$`%IncMSE` )) + geom_bar(stat = "identity") + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))+ xlab("Variable Name") + ylab("Importance %age")
```

Lets plot the predictions vs actual and find out any outliers if present
```{r }
actual_data <- date %>% select(date,actual)

#fetch data from test_set
years_t <- test_set$year
months_t <- test_set$month
day_t <- test_set$day

test_set_date <- test_set %>%
  mutate(date = make_date(year, month, day))
#make df
predicted_data <- test_set_date %>% select(date) %>% mutate(predictions = pred_imp)

plot(actual_data,date$date, type="o", col="blue", pch="l", lty=1, ylim=c(0,110), ylab="Max Temperature in F")
points(predicted_data,y=NULL,col="red", pch=16 ) 
legend(x="topleft",
       ncol = 4,
       legend = c("actual",
                  "predicted"
                  ),
       fill = c("blue","red")
  )
```

As seen, no outliers are present.

# Results

The following table represents average model and different variants of Random Forest Model. 
```{r}
predicted_results %>% knitr::kable()
```

we therefore obsetved the best error and accuracy with the last model where only important features were considered to predict the max temperature. 
As per our model, the predicted temperature is 48.57 whereas the actual max temperature 50, which represents our model to be good.


# Conclusion
So here in this project we used random forest to build a machine learning model for forecasting the max temperature of the last day of the year after using the historical 1 year data of temperature.

We observed that by tunning few hyperparameters we improved the model performance.

We also observed that the model preformance was almost the same infact little improved and the error value was also similar when we build the model using all the features and when we build the model by only using the two most important features. This can conclude that some features do not contribute much in preparing the prediction model and we can ignore those features for saving time.




